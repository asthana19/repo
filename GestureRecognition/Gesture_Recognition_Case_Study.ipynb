{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started. Once you have completed the code you can download the notebook for making a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries and Modules\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up seed as a constant for consistent results for each run\n",
    "\n",
    "\n",
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data path: /home/datasets/Project_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/datasets/Project_data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-59518f49039e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/datasets/Project_data/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mval_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/datasets/Project_data/val.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/datasets/Project_data/train.csv'"
     ]
    }
   ],
   "source": [
    "#Reading the csv for train and validation datasets\n",
    "\n",
    "\n",
    "train_doc = np.random.permutation(open('/home/datasets/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/home/datasets/Project_data/val.csv').readlines())\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for defining generators which will generate batches for train and validation\n",
    "\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = list(range(5,25))\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,20,120,120,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    image=resize(image, (120, 120),anti_aliasing=True, preserve_range=False) #Resizing the image into 120x120\n",
    "                    image = (image - np.min(image))/(np.max(image)- np.min(image)) #Normalising the image pixel values\n",
    "                    \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0]\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1]\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2]\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        #Code for residual data to complete one pass on dataset\n",
    "        if(len(t)%batch_size) != 0:\n",
    "            batch_data = np.zeros((batch_size,20,120,120,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    image=resize(image, (120, 120),anti_aliasing=True, preserve_range=False) #Resizing the image into 120x120\n",
    "                    image = (image - np.min(image))/(np.max(image)- np.min(image)) #Normalising the image pixel values\n",
    "                    \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0]\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1]\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2]\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "#Defining the paths for train and validation dataset, getting current date which is used for naming h5 file\n",
    "\n",
    "\n",
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '/home/datasets/Project_data/train'\n",
    "val_path = '/home/datasets/Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 20\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv3D+MaxPooling3D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making necessary imports for Conv3D and Maxpooling3D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#Defining constants for Model\n",
    "filter_params = [8, 16, 32, 64]\n",
    "dense_params = [256, 128, 5]\n",
    "input_shape = (20, 120, 120, 3)\n",
    "\n",
    "\n",
    "#Model \n",
    "model = Sequential([\n",
    "    Conv3D(filter_params[0], kernel_size=(3, 3, 3), input_shape=input_shape,padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "\n",
    "    Conv3D(filter_params[1], kernel_size=(3, 3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "\n",
    "    Conv3D(filter_params[2], kernel_size=(1, 3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "\n",
    "    Conv3D(filter_params[3], kernel_size=(1, 3, 3), padding='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "\n",
    "    Dense(dense_params[0], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(dense_params[1], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(dense_params[2], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 20, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 10, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 10, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 5, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 5, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 2, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Importing ADAptive Moment Optimiser\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimiser = Adam()\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using generator function to create training and test batches\n",
    "\n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "#Defining model name, filepath for h5 file, checkpoint, callback and LR Reduction \n",
    "\n",
    "\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit` method to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#Defining number of runs for the datasets which dependent on the batch size \n",
    "\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(steps_per_epoch)\n",
    "print(validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6365 - categorical_accuracy: 0.2672Source path =  /home/datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.58134, saving model to model_init_2021-08-0114_55_06.574721/model-00001-1.63648-0.26716-1.58134-0.24000.h5\n",
      "67/67 [==============================] - 128s 2s/step - loss: 1.6365 - categorical_accuracy: 0.2672 - val_loss: 1.5813 - val_categorical_accuracy: 0.2400\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3807 - categorical_accuracy: 0.4000\n",
      "Epoch 00002: val_loss did not improve from 1.58134\n",
      "67/67 [==============================] - 126s 2s/step - loss: 1.3807 - categorical_accuracy: 0.4000 - val_loss: 1.7404 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2442 - categorical_accuracy: 0.4985\n",
      "Epoch 00003: val_loss did not improve from 1.58134\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 126s 2s/step - loss: 1.2442 - categorical_accuracy: 0.4985 - val_loss: 1.7832 - val_categorical_accuracy: 0.3200\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0355 - categorical_accuracy: 0.5687\n",
      "Epoch 00004: val_loss did not improve from 1.58134\n",
      "67/67 [==============================] - 129s 2s/step - loss: 1.0355 - categorical_accuracy: 0.5687 - val_loss: 1.6970 - val_categorical_accuracy: 0.4500\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9261 - categorical_accuracy: 0.6284\n",
      "Epoch 00005: val_loss improved from 1.58134 to 1.17051, saving model to model_init_2021-08-0114_55_06.574721/model-00005-0.92610-0.62836-1.17051-0.51000.h5\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.9261 - categorical_accuracy: 0.6284 - val_loss: 1.1705 - val_categorical_accuracy: 0.5100\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7758 - categorical_accuracy: 0.6806\n",
      "Epoch 00006: val_loss improved from 1.17051 to 1.07876, saving model to model_init_2021-08-0114_55_06.574721/model-00006-0.77584-0.68060-1.07876-0.50000.h5\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.7758 - categorical_accuracy: 0.6806 - val_loss: 1.0788 - val_categorical_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6523 - categorical_accuracy: 0.7418\n",
      "Epoch 00007: val_loss improved from 1.07876 to 0.73564, saving model to model_init_2021-08-0114_55_06.574721/model-00007-0.65231-0.74179-0.73564-0.73000.h5\n",
      "67/67 [==============================] - 131s 2s/step - loss: 0.6523 - categorical_accuracy: 0.7418 - val_loss: 0.7356 - val_categorical_accuracy: 0.7300\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5616 - categorical_accuracy: 0.8015\n",
      "Epoch 00008: val_loss did not improve from 0.73564\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.5616 - categorical_accuracy: 0.8015 - val_loss: 0.8466 - val_categorical_accuracy: 0.7200\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5490 - categorical_accuracy: 0.8030\n",
      "Epoch 00009: val_loss improved from 0.73564 to 0.54622, saving model to model_init_2021-08-0114_55_06.574721/model-00009-0.54899-0.80299-0.54622-0.80000.h5\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.5490 - categorical_accuracy: 0.8030 - val_loss: 0.5462 - val_categorical_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4163 - categorical_accuracy: 0.8478\n",
      "Epoch 00010: val_loss did not improve from 0.54622\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.4163 - categorical_accuracy: 0.8478 - val_loss: 0.6619 - val_categorical_accuracy: 0.7700\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3675 - categorical_accuracy: 0.8612\n",
      "Epoch 00011: val_loss improved from 0.54622 to 0.50937, saving model to model_init_2021-08-0114_55_06.574721/model-00011-0.36748-0.86119-0.50937-0.82000.h5\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.3675 - categorical_accuracy: 0.8612 - val_loss: 0.5094 - val_categorical_accuracy: 0.8200\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2771 - categorical_accuracy: 0.8955\n",
      "Epoch 00012: val_loss improved from 0.50937 to 0.44321, saving model to model_init_2021-08-0114_55_06.574721/model-00012-0.27710-0.89552-0.44321-0.84000.h5\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.2771 - categorical_accuracy: 0.8955 - val_loss: 0.4432 - val_categorical_accuracy: 0.8400\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2694 - categorical_accuracy: 0.9030\n",
      "Epoch 00013: val_loss improved from 0.44321 to 0.31432, saving model to model_init_2021-08-0114_55_06.574721/model-00013-0.26944-0.90299-0.31432-0.89000.h5\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.2694 - categorical_accuracy: 0.9030 - val_loss: 0.3143 - val_categorical_accuracy: 0.8900\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2439 - categorical_accuracy: 0.9119\n",
      "Epoch 00014: val_loss did not improve from 0.31432\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.2439 - categorical_accuracy: 0.9119 - val_loss: 0.3424 - val_categorical_accuracy: 0.8500\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1968 - categorical_accuracy: 0.9358\n",
      "Epoch 00015: val_loss did not improve from 0.31432\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.1968 - categorical_accuracy: 0.9358 - val_loss: 0.6340 - val_categorical_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1495 - categorical_accuracy: 0.9507\n",
      "Epoch 00016: val_loss improved from 0.31432 to 0.28617, saving model to model_init_2021-08-0114_55_06.574721/model-00016-0.14954-0.95075-0.28617-0.90000.h5\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.1495 - categorical_accuracy: 0.9507 - val_loss: 0.2862 - val_categorical_accuracy: 0.9000\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1317 - categorical_accuracy: 0.9537\n",
      "Epoch 00017: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.1317 - categorical_accuracy: 0.9537 - val_loss: 0.4270 - val_categorical_accuracy: 0.8300\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1070 - categorical_accuracy: 0.9701\n",
      "Epoch 00018: val_loss did not improve from 0.28617\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 111s 2s/step - loss: 0.1070 - categorical_accuracy: 0.9701 - val_loss: 0.4892 - val_categorical_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1100 - categorical_accuracy: 0.9657\n",
      "Epoch 00019: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 104s 2s/step - loss: 0.1100 - categorical_accuracy: 0.9657 - val_loss: 0.2983 - val_categorical_accuracy: 0.8900\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0896 - categorical_accuracy: 0.9627\n",
      "Epoch 00020: val_loss did not improve from 0.28617\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0896 - categorical_accuracy: 0.9627 - val_loss: 0.2947 - val_categorical_accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb13435cc50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the Model on Train dataset and Evaluatng on Validation dataset\n",
    "\n",
    "\n",
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy on Train : 96% \n",
    "#Model Accuracy on Validation : 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2D+RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making necessary imports for Conv2D, Maxpooling2D, TimeDistributed, GRU\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, TimeDistributed, GRU\n",
    "\n",
    "\n",
    "#Model\n",
    "model2 = Sequential([\n",
    "    TimeDistributed(Conv2D(filter_params[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape),\n",
    "\n",
    "    TimeDistributed(Conv2D(filter_params[1], (3, 3),padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\n",
    "\n",
    "    TimeDistributed(Conv2D(filter_params[2], (3, 3),padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\n",
    "\n",
    "    TimeDistributed(Conv2D(filter_params[3], (2, 2),padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\n",
    "\n",
    "    TimeDistributed(BatchNormalization()),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    TimeDistributed(Flatten()),\n",
    "\n",
    "    Dense(dense_params[0], activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Dense(dense_params[1], activation='relu'),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    GRU(128, return_sequences=False),\n",
    "    Dense(dense_params[2], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 20, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 20, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 20, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 20, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 20, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 20, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 20, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20, 256)           803072    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               99072     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 950,229\n",
      "Trainable params: 950,101\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = Adam()\n",
    "model2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3181 - categorical_accuracy: 0.4418\n",
      "Epoch 00001: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 107s 2s/step - loss: 1.3181 - categorical_accuracy: 0.4418 - val_loss: 1.5127 - val_categorical_accuracy: 0.3900\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8477 - categorical_accuracy: 0.6821\n",
      "Epoch 00002: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.8477 - categorical_accuracy: 0.6821 - val_loss: 1.4593 - val_categorical_accuracy: 0.3400\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6875 - categorical_accuracy: 0.7507\n",
      "Epoch 00003: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6875 - categorical_accuracy: 0.7507 - val_loss: 1.2738 - val_categorical_accuracy: 0.4500\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4071 - categorical_accuracy: 0.8537\n",
      "Epoch 00004: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.4071 - categorical_accuracy: 0.8537 - val_loss: 1.0710 - val_categorical_accuracy: 0.5600\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2719 - categorical_accuracy: 0.9015\n",
      "Epoch 00005: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.2719 - categorical_accuracy: 0.9015 - val_loss: 1.1027 - val_categorical_accuracy: 0.6100\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2136 - categorical_accuracy: 0.9299\n",
      "Epoch 00006: val_loss did not improve from 0.28617\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.2136 - categorical_accuracy: 0.9299 - val_loss: 1.1128 - val_categorical_accuracy: 0.6300\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0690 - categorical_accuracy: 0.9761\n",
      "Epoch 00007: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 104s 2s/step - loss: 0.0690 - categorical_accuracy: 0.9761 - val_loss: 1.1313 - val_categorical_accuracy: 0.6300\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0272 - categorical_accuracy: 0.9970\n",
      "Epoch 00008: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.0272 - categorical_accuracy: 0.9970 - val_loss: 1.0193 - val_categorical_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0149 - categorical_accuracy: 0.9985\n",
      "Epoch 00009: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 104s 2s/step - loss: 0.0149 - categorical_accuracy: 0.9985 - val_loss: 1.0207 - val_categorical_accuracy: 0.7800\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0077 - categorical_accuracy: 1.0000\n",
      "Epoch 00010: val_loss did not improve from 0.28617\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.0077 - categorical_accuracy: 1.0000 - val_loss: 1.0938 - val_categorical_accuracy: 0.7100\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0060 - categorical_accuracy: 1.0000\n",
      "Epoch 00011: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.0060 - categorical_accuracy: 1.0000 - val_loss: 1.2120 - val_categorical_accuracy: 0.7100\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0048 - categorical_accuracy: 1.0000\n",
      "Epoch 00012: val_loss did not improve from 0.28617\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.0048 - categorical_accuracy: 1.0000 - val_loss: 1.4363 - val_categorical_accuracy: 0.6900\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0048 - categorical_accuracy: 1.0000\n",
      "Epoch 00013: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.0048 - categorical_accuracy: 1.0000 - val_loss: 1.1968 - val_categorical_accuracy: 0.6700\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0034 - categorical_accuracy: 1.0000\n",
      "Epoch 00014: val_loss did not improve from 0.28617\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.0034 - categorical_accuracy: 1.0000 - val_loss: 1.3158 - val_categorical_accuracy: 0.7100\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0043 - categorical_accuracy: 1.0000\n",
      "Epoch 00015: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.0043 - categorical_accuracy: 1.0000 - val_loss: 1.2894 - val_categorical_accuracy: 0.7000\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0042 - categorical_accuracy: 1.0000\n",
      "Epoch 00016: val_loss did not improve from 0.28617\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.0042 - categorical_accuracy: 1.0000 - val_loss: 1.1897 - val_categorical_accuracy: 0.7600\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0033 - categorical_accuracy: 1.0000\n",
      "Epoch 00017: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.0033 - categorical_accuracy: 1.0000 - val_loss: 1.0990 - val_categorical_accuracy: 0.6900\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0027 - categorical_accuracy: 1.0000\n",
      "Epoch 00018: val_loss did not improve from 0.28617\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0027 - categorical_accuracy: 1.0000 - val_loss: 1.1531 - val_categorical_accuracy: 0.7100\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0029 - categorical_accuracy: 1.0000\n",
      "Epoch 00019: val_loss did not improve from 0.28617\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 1.2147 - val_categorical_accuracy: 0.7100\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0034 - categorical_accuracy: 1.0000\n",
      "Epoch 00020: val_loss did not improve from 0.28617\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.0034 - categorical_accuracy: 1.0000 - val_loss: 1.2677 - val_categorical_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb115a35048>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Fitting the Model on Train dataset and Evaluatng on Validation dataset\n",
    "\n",
    "\n",
    "model2.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy on Train dataset : 100%\n",
    "#Model Accuracy on Validation dataset : 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations on Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the Base Model for Conv2D+RNN indicates presence of overfitting whereas the base Conv3D+Maxpooling3D gives better performance with a slight overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  2 12:07:52 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.42.01    Driver Version: 470.42.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:3D:00.0 Off |                  Off |\n",
      "| 30%   49C    P2    90W / 300W |  10839MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#Checking GPU usage before Experiments\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running both Base Models with all Frames, Batch size = 20, Window size = 2, Epochs = 10, Resizing image to 100x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making experiment specific constants and defining custom generator for this experiment\n",
    "batch_size_exp1 = 20\n",
    "num_epochs_exp1 = 10\n",
    "filter_params_exp1 = [8,16,32,64]\n",
    "dense_params_exp1 = [256, 128, 5]\n",
    "input_shape_exp1 = (30,100,100,3)\n",
    "\n",
    "def generator_exp1(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = list(range(30))\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,30,100,100,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    image=resize(image, (100, 100),anti_aliasing=True, preserve_range=False) #Resizing the image into 120x120\n",
    "                    image = (image - np.min(image))/(np.max(image)- np.min(image)) #Normalising the image pixel values\n",
    "                    \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0]\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1]\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2]\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        #Code for residual data to complete one pass on dataset\n",
    "        if(len(t)%batch_size) != 0:\n",
    "            batch_data = np.zeros((batch_size,30,100,100,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    image=resize(image, (100, 100),anti_aliasing=True, preserve_range=False) #Resizing the image into 120x120\n",
    "                    image = (image - np.min(image))/(np.max(image)- np.min(image)) #Normalising the image pixel values\n",
    "                    \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0]\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1]\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2]\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model \n",
    "model3 = Sequential([\n",
    "    Conv3D(filter_params_exp1[0], kernel_size=(2, 2, 2), input_shape=input_shape_exp1,padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D(pool_size=(2,2,2)),\n",
    "\n",
    "    Conv3D(filter_params_exp1[1], kernel_size=(2, 2, 2), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D(pool_size=(2,2,2)),\n",
    "\n",
    "    Conv3D(filter_params_exp1[2], kernel_size=(1, 2, 2), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "\n",
    "    Conv3D(filter_params_exp1[3], kernel_size=(1, 2, 2), padding='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "\n",
    "    Dense(dense_params_exp1[0], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(dense_params_exp1[1], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(dense_params_exp1[2], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_4 (Conv3D)            (None, 30, 100, 100, 8)   200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 100, 100, 8)   32        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 15, 50, 50, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 15, 50, 50, 16)    1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 50, 50, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 7, 25, 25, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 7, 25, 25, 32)     2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 25, 25, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 3, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 3, 12, 12, 64)     8256      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 1, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 635,421\n",
      "Trainable params: 635,309\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = Adam()\n",
    "model3.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_exp1 = generator_exp1(train_path, train_doc, batch_size_exp1)\n",
    "val_generator_exp1 = generator_exp1(val_path, val_doc, batch_size_exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size_exp1) == 0:\n",
    "    steps_per_epoch_exp1 = int(num_train_sequences/batch_size_exp1)\n",
    "else:\n",
    "    steps_per_epoch_exp1 = (num_train_sequences//batch_size_exp1) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps_exp1 = int(num_val_sequences/batch_size_exp1)\n",
    "else:\n",
    "    validation_steps_exp1 = (num_val_sequences//batch_size_exp1) + 1\n",
    "\n",
    "print(steps_per_epoch_exp1)\n",
    "print(validation_steps_exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.6863 - categorical_accuracy: 0.2309Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60893, saving model to model_init_2021-08-0208_28_55.541983/model-00001-2.68628-0.23088-1.60893-0.17000.h5\n",
      "34/34 [==============================] - 182s 5s/step - loss: 2.6863 - categorical_accuracy: 0.2309 - val_loss: 1.6089 - val_categorical_accuracy: 0.1700\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.5372 - categorical_accuracy: 0.3088\n",
      "Epoch 00002: val_loss improved from 1.60893 to 1.60471, saving model to model_init_2021-08-0208_28_55.541983/model-00002-1.53723-0.30882-1.60471-0.22000.h5\n",
      "34/34 [==============================] - 163s 5s/step - loss: 1.5372 - categorical_accuracy: 0.3088 - val_loss: 1.6047 - val_categorical_accuracy: 0.2200\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.4145 - categorical_accuracy: 0.3985\n",
      "Epoch 00003: val_loss did not improve from 1.60471\n",
      "34/34 [==============================] - 167s 5s/step - loss: 1.4145 - categorical_accuracy: 0.3985 - val_loss: 1.6292 - val_categorical_accuracy: 0.1800\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.3007 - categorical_accuracy: 0.4559\n",
      "Epoch 00004: val_loss did not improve from 1.60471\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "34/34 [==============================] - 167s 5s/step - loss: 1.3007 - categorical_accuracy: 0.4559 - val_loss: 1.8300 - val_categorical_accuracy: 0.2200\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1038 - categorical_accuracy: 0.5515\n",
      "Epoch 00005: val_loss did not improve from 1.60471\n",
      "34/34 [==============================] - 163s 5s/step - loss: 1.1038 - categorical_accuracy: 0.5515 - val_loss: 1.9825 - val_categorical_accuracy: 0.1800\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9826 - categorical_accuracy: 0.6103\n",
      "Epoch 00006: val_loss did not improve from 1.60471\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "34/34 [==============================] - 159s 5s/step - loss: 0.9826 - categorical_accuracy: 0.6103 - val_loss: 1.9981 - val_categorical_accuracy: 0.2100\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9198 - categorical_accuracy: 0.6206\n",
      "Epoch 00007: val_loss did not improve from 1.60471\n",
      "34/34 [==============================] - 156s 5s/step - loss: 0.9198 - categorical_accuracy: 0.6206 - val_loss: 2.0169 - val_categorical_accuracy: 0.2100\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8552 - categorical_accuracy: 0.6985\n",
      "Epoch 00008: val_loss did not improve from 1.60471\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "34/34 [==============================] - 183s 5s/step - loss: 0.8552 - categorical_accuracy: 0.6985 - val_loss: 2.1974 - val_categorical_accuracy: 0.2600\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8124 - categorical_accuracy: 0.6868\n",
      "Epoch 00009: val_loss did not improve from 1.60471\n",
      "34/34 [==============================] - 187s 6s/step - loss: 0.8124 - categorical_accuracy: 0.6868 - val_loss: 1.8038 - val_categorical_accuracy: 0.2600\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7791 - categorical_accuracy: 0.7088\n",
      "Epoch 00010: val_loss did not improve from 1.60471\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "34/34 [==============================] - 184s 5s/step - loss: 0.7791 - categorical_accuracy: 0.7088 - val_loss: 1.8064 - val_categorical_accuracy: 0.3200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4f81f37f28>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_generator_exp1, steps_per_epoch=steps_per_epoch_exp1, epochs=num_epochs_exp1, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator_exp1, \n",
    "                    validation_steps=validation_steps_exp1, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy on Train dataset : 70%\n",
    "#Model Accuracy on Validation dataset : 32%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model4 = Sequential([\n",
    "    TimeDistributed(Conv2D(filter_params_exp1[0], (2, 2), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape_exp1),\n",
    "\n",
    "    TimeDistributed(Conv2D(filter_params_exp1[1], (2, 2),padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\n",
    "\n",
    "    TimeDistributed(Conv2D(filter_params_exp1[2], (2, 2),padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\n",
    "\n",
    "    TimeDistributed(Conv2D(filter_params_exp1[3], (2, 2),padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\n",
    "\n",
    "    TimeDistributed(BatchNormalization()),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    TimeDistributed(Flatten()),\n",
    "\n",
    "    Dense(dense_params_exp1[0], activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Dense(dense_params_exp1[1], activation='relu'),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    GRU(128, return_sequences=False),\n",
    "    Dense(dense_params_exp1[2], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_9 (TimeDist (None, 30, 50, 50, 8)     104       \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 30, 50, 50, 16)    528       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 30, 25, 25, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 30, 25, 25, 32)    2080      \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 30, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 30, 12, 12, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 30, 6, 6, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 30, 6, 6, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 6, 6, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 30, 2304)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 30, 256)           590080    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               99072     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 733,917\n",
      "Trainable params: 733,789\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = Adam()\n",
    "model4.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.2405 - categorical_accuracy: 0.4794\n",
      "Epoch 00001: val_loss improved from 1.60471 to 1.54130, saving model to model_init_2021-08-0208_28_55.541983/model-00001-1.24049-0.47941-1.54130-0.34000.h5\n",
      "34/34 [==============================] - 173s 5s/step - loss: 1.2405 - categorical_accuracy: 0.4794 - val_loss: 1.5413 - val_categorical_accuracy: 0.3400\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7789 - categorical_accuracy: 0.6985\n",
      "Epoch 00002: val_loss improved from 1.54130 to 1.47270, saving model to model_init_2021-08-0208_28_55.541983/model-00002-0.77886-0.69853-1.47270-0.39000.h5\n",
      "34/34 [==============================] - 170s 5s/step - loss: 0.7789 - categorical_accuracy: 0.6985 - val_loss: 1.4727 - val_categorical_accuracy: 0.3900\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5165 - categorical_accuracy: 0.8059\n",
      "Epoch 00003: val_loss improved from 1.47270 to 1.25394, saving model to model_init_2021-08-0208_28_55.541983/model-00003-0.51645-0.80588-1.25394-0.44000.h5\n",
      "34/34 [==============================] - 165s 5s/step - loss: 0.5165 - categorical_accuracy: 0.8059 - val_loss: 1.2539 - val_categorical_accuracy: 0.4400\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2689 - categorical_accuracy: 0.8956\n",
      "Epoch 00004: val_loss did not improve from 1.25394\n",
      "34/34 [==============================] - 162s 5s/step - loss: 0.2689 - categorical_accuracy: 0.8956 - val_loss: 1.3075 - val_categorical_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1374 - categorical_accuracy: 0.9515\n",
      "Epoch 00005: val_loss improved from 1.25394 to 1.13712, saving model to model_init_2021-08-0208_28_55.541983/model-00005-0.13738-0.95147-1.13712-0.58000.h5\n",
      "34/34 [==============================] - 177s 5s/step - loss: 0.1374 - categorical_accuracy: 0.9515 - val_loss: 1.1371 - val_categorical_accuracy: 0.5800\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0476 - categorical_accuracy: 0.9882\n",
      "Epoch 00006: val_loss improved from 1.13712 to 0.92880, saving model to model_init_2021-08-0208_28_55.541983/model-00006-0.04765-0.98824-0.92880-0.70000.h5\n",
      "34/34 [==============================] - 177s 5s/step - loss: 0.0476 - categorical_accuracy: 0.9882 - val_loss: 0.9288 - val_categorical_accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0301 - categorical_accuracy: 0.9912\n",
      "Epoch 00007: val_loss improved from 0.92880 to 0.79324, saving model to model_init_2021-08-0208_28_55.541983/model-00007-0.03006-0.99118-0.79324-0.77000.h5\n",
      "34/34 [==============================] - 178s 5s/step - loss: 0.0301 - categorical_accuracy: 0.9912 - val_loss: 0.7932 - val_categorical_accuracy: 0.7700\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0427 - categorical_accuracy: 0.9824\n",
      "Epoch 00008: val_loss improved from 0.79324 to 0.72895, saving model to model_init_2021-08-0208_28_55.541983/model-00008-0.04274-0.98235-0.72895-0.72000.h5\n",
      "34/34 [==============================] - 169s 5s/step - loss: 0.0427 - categorical_accuracy: 0.9824 - val_loss: 0.7290 - val_categorical_accuracy: 0.7200\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0497 - categorical_accuracy: 0.9794\n",
      "Epoch 00009: val_loss did not improve from 0.72895\n",
      "34/34 [==============================] - 167s 5s/step - loss: 0.0497 - categorical_accuracy: 0.9794 - val_loss: 1.0721 - val_categorical_accuracy: 0.5900\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1421 - categorical_accuracy: 0.9471\n",
      "Epoch 00010: val_loss did not improve from 0.72895\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "34/34 [==============================] - 161s 5s/step - loss: 0.1421 - categorical_accuracy: 0.9471 - val_loss: 1.7810 - val_categorical_accuracy: 0.5600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4f81f37f98>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(train_generator_exp1, steps_per_epoch=steps_per_epoch, epochs=num_epochs_exp1, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator_exp1, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy on Train dataset : ~95%\n",
    "#Model Accuracy on Validation dataset : 56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations on Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like this experiment didnt yield good result, we still face a problem of overfitting. Hence we will try to make our models less complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reducing Base Models' complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential([\n",
    "    Conv3D(filter_params[1], kernel_size=(2, 2, 2), input_shape=input_shape,padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D(pool_size=(2,2,2)),\n",
    "\n",
    "    #Conv3D(filter_params[1], kernel_size=(2, 2, 2), padding='same', activation='relu'),\n",
    "    #BatchNormalization(),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "\n",
    "    Conv3D(filter_params[2], kernel_size=(1, 2, 2), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "\n",
    "    Conv3D(filter_params[3], kernel_size=(1, 2, 2), padding='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "\n",
    "    Dense(dense_params[1], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    #Dense(dense_params[1], activation='relu'),\n",
    "    #Dropout(0.5),\n",
    "    \n",
    "    Dense(dense_params[2], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 20, 120, 120, 16)  400       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 20, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 10, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 5, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 5, 30, 30, 32)     2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 5, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 2, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 2, 15, 15, 64)     8256      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 413,109\n",
      "Trainable params: 413,013\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = Adam()\n",
    "model5.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9626 - categorical_accuracy: 0.5985\n",
      "Epoch 00001: val_loss did not improve from 0.72895\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.9626 - categorical_accuracy: 0.5985 - val_loss: 2.0495 - val_categorical_accuracy: 0.2800\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8040 - categorical_accuracy: 0.7030\n",
      "Epoch 00002: val_loss did not improve from 0.72895\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.8040 - categorical_accuracy: 0.7030 - val_loss: 2.0265 - val_categorical_accuracy: 0.3200\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7363 - categorical_accuracy: 0.7313\n",
      "Epoch 00003: val_loss did not improve from 0.72895\n",
      "67/67 [==============================] - 99s 1s/step - loss: 0.7363 - categorical_accuracy: 0.7313 - val_loss: 1.9812 - val_categorical_accuracy: 0.2200\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6236 - categorical_accuracy: 0.7657\n",
      "Epoch 00004: val_loss did not improve from 0.72895\n",
      "67/67 [==============================] - 99s 1s/step - loss: 0.6236 - categorical_accuracy: 0.7657 - val_loss: 1.6922 - val_categorical_accuracy: 0.3600\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5644 - categorical_accuracy: 0.7821\n",
      "Epoch 00005: val_loss did not improve from 0.72895\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.5644 - categorical_accuracy: 0.7821 - val_loss: 1.0924 - val_categorical_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4414 - categorical_accuracy: 0.8358\n",
      "Epoch 00006: val_loss did not improve from 0.72895\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.4414 - categorical_accuracy: 0.8358 - val_loss: 0.9412 - val_categorical_accuracy: 0.5800\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3946 - categorical_accuracy: 0.8478\n",
      "Epoch 00007: val_loss did not improve from 0.72895\n",
      "67/67 [==============================] - 100s 1s/step - loss: 0.3946 - categorical_accuracy: 0.8478 - val_loss: 0.7654 - val_categorical_accuracy: 0.6600\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3594 - categorical_accuracy: 0.8746\n",
      "Epoch 00008: val_loss improved from 0.72895 to 0.55808, saving model to model_init_2021-08-0208_28_55.541983/model-00008-0.35939-0.87463-0.55808-0.82000.h5\n",
      "67/67 [==============================] - 100s 1s/step - loss: 0.3594 - categorical_accuracy: 0.8746 - val_loss: 0.5581 - val_categorical_accuracy: 0.8200\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3011 - categorical_accuracy: 0.8866\n",
      "Epoch 00009: val_loss improved from 0.55808 to 0.29814, saving model to model_init_2021-08-0208_28_55.541983/model-00009-0.30106-0.88657-0.29814-0.98000.h5\n",
      "67/67 [==============================] - 99s 1s/step - loss: 0.3011 - categorical_accuracy: 0.8866 - val_loss: 0.2981 - val_categorical_accuracy: 0.9800\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2675 - categorical_accuracy: 0.8970\n",
      "Epoch 00010: val_loss did not improve from 0.29814\n",
      "67/67 [==============================] - 101s 2s/step - loss: 0.2675 - categorical_accuracy: 0.8970 - val_loss: 0.3651 - val_categorical_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2242 - categorical_accuracy: 0.9179\n",
      "Epoch 00011: val_loss did not improve from 0.29814\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 94s 1s/step - loss: 0.2242 - categorical_accuracy: 0.9179 - val_loss: 0.3474 - val_categorical_accuracy: 0.9200\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1932 - categorical_accuracy: 0.9299\n",
      "Epoch 00012: val_loss did not improve from 0.29814\n",
      "67/67 [==============================] - 96s 1s/step - loss: 0.1932 - categorical_accuracy: 0.9299 - val_loss: 0.3380 - val_categorical_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1543 - categorical_accuracy: 0.9493\n",
      "Epoch 00013: val_loss did not improve from 0.29814\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.1543 - categorical_accuracy: 0.9493 - val_loss: 0.4951 - val_categorical_accuracy: 0.8600\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1251 - categorical_accuracy: 0.9522\n",
      "Epoch 00014: val_loss improved from 0.29814 to 0.14157, saving model to model_init_2021-08-0208_28_55.541983/model-00014-0.12511-0.95224-0.14157-0.96000.h5\n",
      "67/67 [==============================] - 99s 1s/step - loss: 0.1251 - categorical_accuracy: 0.9522 - val_loss: 0.1416 - val_categorical_accuracy: 0.9600\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1138 - categorical_accuracy: 0.9701\n",
      "Epoch 00015: val_loss did not improve from 0.14157\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.1138 - categorical_accuracy: 0.9701 - val_loss: 0.3345 - val_categorical_accuracy: 0.9200\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1454 - categorical_accuracy: 0.9567\n",
      "Epoch 00016: val_loss did not improve from 0.14157\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.1454 - categorical_accuracy: 0.9567 - val_loss: 0.2819 - val_categorical_accuracy: 0.9000\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1107 - categorical_accuracy: 0.9627\n",
      "Epoch 00017: val_loss did not improve from 0.14157\n",
      "67/67 [==============================] - 100s 1s/step - loss: 0.1107 - categorical_accuracy: 0.9627 - val_loss: 0.1967 - val_categorical_accuracy: 0.9800\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1207 - categorical_accuracy: 0.9537\n",
      "Epoch 00018: val_loss did not improve from 0.14157\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "67/67 [==============================] - 93s 1s/step - loss: 0.1207 - categorical_accuracy: 0.9537 - val_loss: 0.1692 - val_categorical_accuracy: 0.9800\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1147 - categorical_accuracy: 0.9612\n",
      "Epoch 00019: val_loss did not improve from 0.14157\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.1147 - categorical_accuracy: 0.9612 - val_loss: 0.4890 - val_categorical_accuracy: 0.9000\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1030 - categorical_accuracy: 0.9687\n",
      "Epoch 00020: val_loss did not improve from 0.14157\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "67/67 [==============================] - 97s 1s/step - loss: 0.1030 - categorical_accuracy: 0.9687 - val_loss: 0.1672 - val_categorical_accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4f6b9d67b8>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy on Train dataset : ~97%\n",
    "#Model Accuracy on Validation dataset : 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model6 = Sequential([\n",
    "    TimeDistributed(Conv2D(filter_params[0], (2, 2), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape),\n",
    "\n",
    "    TimeDistributed(Conv2D(filter_params[1], (2, 2),padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\n",
    "\n",
    "    TimeDistributed(Conv2D(filter_params[2], (2, 2),padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\n",
    "\n",
    "    #TimeDistributed(Conv2D(filter_params[3], (2, 2),padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\n",
    "\n",
    "    TimeDistributed(BatchNormalization()),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    TimeDistributed(Flatten()),\n",
    "\n",
    "    Dense(dense_params[0], activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    #Dense(dense_params[1], activation='relu'),\n",
    "    #Dropout(0.25),\n",
    "\n",
    "    GRU(dense_params[1], return_sequences=False),\n",
    "    Dense(dense_params[2], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_32 (TimeDis (None, 20, 60, 60, 8)     104       \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 20, 60, 60, 16)    528       \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 20, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 20, 30, 30, 32)    2080      \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 20, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 20, 7, 7, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 20, 7, 7, 32)      128       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 20, 7, 7, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 20, 1568)          0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 20, 256)           401664    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 128)               148224    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 553,373\n",
      "Trainable params: 553,309\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = Adam()\n",
    "model6.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2041 - categorical_accuracy: 0.5104\n",
      "Epoch 00001: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 115s 2s/step - loss: 1.2041 - categorical_accuracy: 0.5104 - val_loss: 1.5203 - val_categorical_accuracy: 0.3200\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6283 - categorical_accuracy: 0.7701\n",
      "Epoch 00002: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 131s 2s/step - loss: 0.6283 - categorical_accuracy: 0.7701 - val_loss: 1.3333 - val_categorical_accuracy: 0.5100\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3700 - categorical_accuracy: 0.8672\n",
      "Epoch 00003: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.3700 - categorical_accuracy: 0.8672 - val_loss: 1.5068 - val_categorical_accuracy: 0.2300\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1701 - categorical_accuracy: 0.9433\n",
      "Epoch 00004: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.1701 - categorical_accuracy: 0.9433 - val_loss: 1.0291 - val_categorical_accuracy: 0.5800\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0927 - categorical_accuracy: 0.9746\n",
      "Epoch 00005: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 120s 2s/step - loss: 0.0927 - categorical_accuracy: 0.9746 - val_loss: 0.8943 - val_categorical_accuracy: 0.5500\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0683 - categorical_accuracy: 0.9731\n",
      "Epoch 00006: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0683 - categorical_accuracy: 0.9731 - val_loss: 2.5247 - val_categorical_accuracy: 0.3700\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0688 - categorical_accuracy: 0.9761\n",
      "Epoch 00007: val_loss did not improve from 0.71733\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0688 - categorical_accuracy: 0.9761 - val_loss: 0.9027 - val_categorical_accuracy: 0.6300\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0399 - categorical_accuracy: 0.9881\n",
      "Epoch 00008: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0399 - categorical_accuracy: 0.9881 - val_loss: 1.0318 - val_categorical_accuracy: 0.6700\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0113 - categorical_accuracy: 0.9985\n",
      "Epoch 00009: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 127s 2s/step - loss: 0.0113 - categorical_accuracy: 0.9985 - val_loss: 0.8090 - val_categorical_accuracy: 0.7600\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0059 - categorical_accuracy: 1.0000\n",
      "Epoch 00010: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 128s 2s/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 0.8429 - val_categorical_accuracy: 0.7200\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0052 - categorical_accuracy: 1.0000\n",
      "Epoch 00011: val_loss did not improve from 0.71733\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 129s 2s/step - loss: 0.0052 - categorical_accuracy: 1.0000 - val_loss: 0.9182 - val_categorical_accuracy: 0.6800\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0037 - categorical_accuracy: 1.0000\n",
      "Epoch 00012: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 120s 2s/step - loss: 0.0037 - categorical_accuracy: 1.0000 - val_loss: 0.9077 - val_categorical_accuracy: 0.6900\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0025 - categorical_accuracy: 1.0000\n",
      "Epoch 00013: val_loss did not improve from 0.71733\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 120s 2s/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 1.0044 - val_categorical_accuracy: 0.6900\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0018 - categorical_accuracy: 1.0000\n",
      "Epoch 00014: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.9162 - val_categorical_accuracy: 0.7000\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 1.0000\n",
      "Epoch 00015: val_loss did not improve from 0.71733\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.9661 - val_categorical_accuracy: 0.6800\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 1.0000\n",
      "Epoch 00016: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.7536 - val_categorical_accuracy: 0.7300\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 1.0000\n",
      "Epoch 00017: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.8770 - val_categorical_accuracy: 0.7200\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 1.0000\n",
      "Epoch 00018: val_loss did not improve from 0.71733\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.9613 - val_categorical_accuracy: 0.6900\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000\n",
      "Epoch 00019: val_loss did not improve from 0.71733\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.8988 - val_categorical_accuracy: 0.7000\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 1.0000\n",
      "Epoch 00020: val_loss did not improve from 0.71733\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.9222 - val_categorical_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7380955be0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy on Train dataset : 100%\n",
    "#Model Accuracy on Validation dataset : 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations on Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5 (Conv3D+Maxpooling3D) gave the best performance overall after reducing the model complexity, whereas the Model 6 (Conv2D+RNN) overfit the train data even with reducing the complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import mobilenet\n",
    "\n",
    "model7 = Sequential([\n",
    "        TimeDistributed(mobilenet.MobileNet(weights='imagenet', include_top=False), input_shape=input_shape),\n",
    "    \n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "    \n",
    "        TimeDistributed(Flatten()),\n",
    "\n",
    "        GRU(dense_params[1], return_sequences=False),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Dense(dense_params[1],activation='relu'),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Dense(dense_params[2], activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_68 (TimeDis (None, 20, 3, 3, 1024)    3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_69 (TimeDis (None, 20, 3, 3, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "time_distributed_70 (TimeDis (None, 20, 1, 1, 1024)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_71 (TimeDis (None, 20, 1024)          0         \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 128)               443136    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,693,253\n",
      "Trainable params: 3,669,317\n",
      "Non-trainable params: 23,936\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = Adam()\n",
    "model7.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8615 - categorical_accuracy: 0.6687\n",
      "Epoch 00001: val_loss improved from 0.71733 to 0.50663, saving model to model_init_2021-08-0212_07_23.286194/model-00001-0.86149-0.66866-0.50663-0.81000.h5\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.8615 - categorical_accuracy: 0.6687 - val_loss: 0.5066 - val_categorical_accuracy: 0.8100\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3931 - categorical_accuracy: 0.8627\n",
      "Epoch 00002: val_loss did not improve from 0.50663\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.3931 - categorical_accuracy: 0.8627 - val_loss: 0.7027 - val_categorical_accuracy: 0.7100\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2555 - categorical_accuracy: 0.9104\n",
      "Epoch 00003: val_loss improved from 0.50663 to 0.30205, saving model to model_init_2021-08-0212_07_23.286194/model-00003-0.25553-0.91045-0.30205-0.89000.h5\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.2555 - categorical_accuracy: 0.9104 - val_loss: 0.3021 - val_categorical_accuracy: 0.8900\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1773 - categorical_accuracy: 0.9522\n",
      "Epoch 00004: val_loss did not improve from 0.30205\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.1773 - categorical_accuracy: 0.9522 - val_loss: 0.3377 - val_categorical_accuracy: 0.8900\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1413 - categorical_accuracy: 0.9567\n",
      "Epoch 00005: val_loss improved from 0.30205 to 0.13884, saving model to model_init_2021-08-0212_07_23.286194/model-00005-0.14126-0.95672-0.13884-0.95000.h5\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.1413 - categorical_accuracy: 0.9567 - val_loss: 0.1388 - val_categorical_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2161 - categorical_accuracy: 0.9358\n",
      "Epoch 00006: val_loss improved from 0.13884 to 0.11505, saving model to model_init_2021-08-0212_07_23.286194/model-00006-0.21607-0.93582-0.11505-0.97000.h5\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.2161 - categorical_accuracy: 0.9358 - val_loss: 0.1151 - val_categorical_accuracy: 0.9700\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1422 - categorical_accuracy: 0.9507\n",
      "Epoch 00007: val_loss did not improve from 0.11505\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.1422 - categorical_accuracy: 0.9507 - val_loss: 0.1672 - val_categorical_accuracy: 0.9400\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0957 - categorical_accuracy: 0.9672\n",
      "Epoch 00008: val_loss did not improve from 0.11505\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0957 - categorical_accuracy: 0.9672 - val_loss: 0.3791 - val_categorical_accuracy: 0.9200\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0940 - categorical_accuracy: 0.9746\n",
      "Epoch 00009: val_loss did not improve from 0.11505\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0940 - categorical_accuracy: 0.9746 - val_loss: 0.2048 - val_categorical_accuracy: 0.9600\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0593 - categorical_accuracy: 0.9851\n",
      "Epoch 00010: val_loss did not improve from 0.11505\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.0593 - categorical_accuracy: 0.9851 - val_loss: 0.1191 - val_categorical_accuracy: 0.9500\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0297 - categorical_accuracy: 0.9925\n",
      "Epoch 00011: val_loss did not improve from 0.11505\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0297 - categorical_accuracy: 0.9925 - val_loss: 0.1424 - val_categorical_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0088 - categorical_accuracy: 1.0000\n",
      "Epoch 00012: val_loss did not improve from 0.11505\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0088 - categorical_accuracy: 1.0000 - val_loss: 0.1399 - val_categorical_accuracy: 0.9500\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0162 - categorical_accuracy: 0.9970\n",
      "Epoch 00013: val_loss did not improve from 0.11505\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0162 - categorical_accuracy: 0.9970 - val_loss: 0.1648 - val_categorical_accuracy: 0.9300\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0104 - categorical_accuracy: 0.9970\n",
      "Epoch 00014: val_loss improved from 0.11505 to 0.11423, saving model to model_init_2021-08-0212_07_23.286194/model-00014-0.01038-0.99701-0.11423-0.95000.h5\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0104 - categorical_accuracy: 0.9970 - val_loss: 0.1142 - val_categorical_accuracy: 0.9500\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0065 - categorical_accuracy: 1.0000\n",
      "Epoch 00015: val_loss improved from 0.11423 to 0.11354, saving model to model_init_2021-08-0212_07_23.286194/model-00015-0.00648-1.00000-0.11354-0.93000.h5\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0065 - categorical_accuracy: 1.0000 - val_loss: 0.1135 - val_categorical_accuracy: 0.9300\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0049 - categorical_accuracy: 1.0000\n",
      "Epoch 00016: val_loss did not improve from 0.11354\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0049 - categorical_accuracy: 1.0000 - val_loss: 0.1722 - val_categorical_accuracy: 0.9400\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0118 - categorical_accuracy: 0.9970\n",
      "Epoch 00017: val_loss did not improve from 0.11354\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0118 - categorical_accuracy: 0.9970 - val_loss: 0.1431 - val_categorical_accuracy: 0.9300\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0078 - categorical_accuracy: 0.9985\n",
      "Epoch 00018: val_loss did not improve from 0.11354\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0078 - categorical_accuracy: 0.9985 - val_loss: 0.1245 - val_categorical_accuracy: 0.9300\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0081 - categorical_accuracy: 0.9985\n",
      "Epoch 00019: val_loss improved from 0.11354 to 0.09543, saving model to model_init_2021-08-0212_07_23.286194/model-00019-0.00810-0.99851-0.09543-0.97000.h5\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0081 - categorical_accuracy: 0.9985 - val_loss: 0.0954 - val_categorical_accuracy: 0.9700\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0034 - categorical_accuracy: 1.0000\n",
      "Epoch 00020: val_loss did not improve from 0.09543\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.0034 - categorical_accuracy: 1.0000 - val_loss: 0.1337 - val_categorical_accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f730ee0ea90>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy on Train dataset : 100%\n",
    "#Model Accuracy on Validation dataset : 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations on Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning did help in getting a good accuracies on both Train (100%) and Validation (95%), but it is more complex then other models (highest number of parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating out base Models and conducting various experiments with them based on number of images per video, image cropping, images resizing, image normalizing, number of parameters and finally employing transfer learning\n",
    "\n",
    "We will choose Model 5 (Conv3D+MaxPooling3D with reduced complexity) as our final model as it gives best performance with lower number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Predicting on Final Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_final = load_model('model_init_2021-08-0208_28_55.541983/model-00014-0.12511-0.95224-0.14157-0.96000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /home/datasets/Project_data/train ; batch size = 10\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test_generator = generator(train_path, train_doc, batch_size)\n",
    "batch_data, batch_labels=next(test_generator)\n",
    "print(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 1 1 3 4 0 4 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(model_final.predict(batch_data[:,:,:,:,:]),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
